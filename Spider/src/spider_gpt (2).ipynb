{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "import sqlite3\n",
    "import logging\n",
    "import mysql.connector\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up LLMs\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "#gpt\n",
    "api_key_gpt=os.getenv('CHATGPT_API_KEY')\n",
    "client = OpenAI(\n",
    "  api_key=api_key_gpt,\n",
    ")\n",
    "\n",
    "#gemini\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY_FLASH\"])\n",
    "modelGemini=genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "#llama\n",
    "api_key_llama=os.getenv(\"LLAMA_API_KEY\")\n",
    "client = OpenAI(\n",
    "    api_key = api_key_llama,\n",
    "    base_url = \"https://api.llama-api.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResponse(prompt,llm):\n",
    "    # print(f\"User:\\n{prompt}\\n\\n\")\n",
    "    if llm=='gpt':\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "        )\n",
    "        response=chat_completion.choices[0].message.content\n",
    "        # print(f\"LLM:\\n{response}\\n\\n\")\n",
    "        return response\n",
    "    elif llm=='gemini':\n",
    "         #gemini response limit mitigation,\n",
    "        response = modelGemini.generate_content(prompt)\n",
    "        # print(f\"LLM:\\n{response.text}\\n\\n\")\n",
    "        return response.text\n",
    "    elif llm=='llama':\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-13b-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        response=response.choices[0].message.content\n",
    "        # print(f\"LLM:\\n{response}\\n\\n\")\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = printResponse(\"What is the capital of India?\",'gemini')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def execute_query(database_path, query):\n",
    "    try:\n",
    "        conn = sqlite3.connect(database_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "        conn.close()\n",
    "        return results\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        with open('logs/incorrectGeminiLog.txt', 'a') as f:\n",
    "            f.write(f\"\\nError that occured:\\n{e}\\n\\n\")\n",
    "        return None\n",
    "\n",
    "def get_first_row_with_columns(database_path, table_name):\n",
    "    try:\n",
    "        conn = sqlite3.connect(database_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Get column names\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns = [info[1] for info in cursor.fetchall()]\n",
    "        \n",
    "        # Get the first row\n",
    "        cursor.execute(f\"SELECT * FROM {table_name} LIMIT 1\")\n",
    "        first_row = cursor.fetchone()\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        return columns, first_row\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        with open('logs/incorrectGeminiLog.txt', 'a') as f:\n",
    "            f.write(f\"\\nError that occurred:\\n{e}\\n\\n\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getDbSchemaMapping(dbFolderPath):\n",
    "    count = 0\n",
    "    schema_array = {}\n",
    "    for folder in os.listdir(dbFolderPath):\n",
    "        count += 1\n",
    "        folder_path = os.path.join(dbFolderPath, folder)\n",
    "        if os.path.exists(folder_path):\n",
    "            json_data = None\n",
    "            table_info = []\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.json'):\n",
    "                    json_file_path = os.path.join(folder_path, file_name)\n",
    "                    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                        try:\n",
    "                            json_data = json.load(file)\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"Error decoding JSON in file {json_file_path}: {e}\")\n",
    "                            continue\n",
    "            \n",
    "            db_file_path = os.path.join(folder_path, f\"{folder}.sqlite\")\n",
    "            if json_data:\n",
    "                if 'tables' in json_data:\n",
    "                    final_table_info = {}\n",
    "                    for table in json_data['tables']:\n",
    "                        table_name = table['name']\n",
    "                        columns, first_row = get_first_row_with_columns(db_file_path, table_name)\n",
    "                        table_info.append((table_name, columns, first_row))\n",
    "                    \n",
    "                        \n",
    "                    schema_array[folder] = {\n",
    "                        \"schema\": json_data,\n",
    "                        \"table_info\": table_info\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"'tables' key not found in JSON data for folder: {folder_path}\")\n",
    "                    schema_array[folder] = {\n",
    "                        \"schema\": json_data,\n",
    "                        \"table_info\": table_info\n",
    "                    }\n",
    "            else:\n",
    "                print(f\"JSON file not found for folder: {folder_path}\")\n",
    "    print(count)\n",
    "    return schema_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tableJsonPath,cleanDataPath):\n",
    "\n",
    "    with open(tableJsonPath,\"r\") as f:\n",
    "        tables_data=json.load(f)\n",
    "\n",
    "    database = {}\n",
    "\n",
    "    with open(cleanDataPath, 'r') as f:\n",
    "\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            db_id = data.get('db_id')\n",
    "            query = data.get('query')\n",
    "            question = data.get('question')\n",
    "            query_toks=data.get('query_toks')\n",
    "\n",
    "            word_freq={}        \n",
    "            for item in tables_data:\n",
    "                if item['db_id']==db_id:\n",
    "                    for table_name in item[\"table_names_original\"]:\n",
    "                        word_freq[table_name.lower()]=1\n",
    "\n",
    "            if db_id not in database:\n",
    "                database[db_id] = {'query': [], 'question': [], 'query_toks': [], 'tables': []}\n",
    "\n",
    "            interim_map={}\n",
    "            table_list=[]\n",
    "            for query_tok in query_toks:\n",
    "                if query_tok.lower() in word_freq:\n",
    "                    if query_tok.lower() not in interim_map:\n",
    "                        interim_map[query_tok.lower()]=1\n",
    "                        table_list.append(query_tok.lower())\n",
    "            \n",
    "            database[db_id]['query'].append(query)\n",
    "            database[db_id]['question'].append(question)\n",
    "            database[db_id]['query_toks'].append(query_toks)\n",
    "            database[db_id]['tables'].append(table_list)\n",
    "            \n",
    "\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_array = getDbSchemaMapping('F:/OneDrive/Desktop/Study/NLP_ResearchProject/Project/spider/database')\n",
    "databases = get_data('F:/OneDrive/Desktop/Study/NLP_ResearchProject/Project/spider/tables.json','F:/OneDrive/Desktop/Study/NLP_ResearchProject/Project/spider/train_spider_main_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_dataset = []\n",
    "easy_dataset = []\n",
    "\n",
    "for folder, data in schema_array.items():\n",
    "    schema = data['schema']\n",
    "    table_info = data['table_info']\n",
    "    length = len(table_info)\n",
    "\n",
    "    if length >= 6:\n",
    "        hard_dataset.append(folder)\n",
    "    else:\n",
    "        easy_dataset.append(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schema_array['school_bus']['table_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder, data in schema_array.items():\n",
    "    print(f\"Folder: {folder}\")\n",
    "    \n",
    "    schema = data.get('schema', {})\n",
    "    print(f\"Schema: {schema}\")\n",
    "    \n",
    "    table_info = data.get('table_info', [])\n",
    "    for table in table_info:\n",
    "        table_name, columns, first_row = table\n",
    "        print(f\"  Table Name: {table_name}\")\n",
    "        print(f\"  Columns: {columns}\")\n",
    "        print(f\"  First Row: {first_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(databases))\n",
    "print(len(schema_array))\n",
    "databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schema_array['insurance_fnol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database folder path\n",
    "db_folder_path = 'F:/OneDrive/Desktop/Study/NLP_ResearchProject/Project/spider/database'\n",
    "import re\n",
    "\n",
    "def extract_table_descriptions(response):\n",
    "    # Define the pattern to extract table_name and table_description\n",
    "    pattern = r\"# Table (\\w+)\\s*\\n(.+?)\\n\"\n",
    "    matches = re.findall(pattern, response, re.DOTALL)\n",
    "\n",
    "    # Create a dictionary {table_name: table_description}\n",
    "    table_extraction_dict = {match[0]: match[1].strip() for match in matches}\n",
    "    \n",
    "    return table_extraction_dict\n",
    "\n",
    "\n",
    "def convert_to_list(results):\n",
    "    final_list = []\n",
    "    if not results: return final_list\n",
    "    for row in results:\n",
    "        final_list.append(tuple(sorted(list(row), key=str)))\n",
    "    return final_list\n",
    "\n",
    "\n",
    "def compare_queries(db_name, db_folder_path, generated_query, original_query):\n",
    "    db_path = os.path.join(db_folder_path, db_name, db_name + '.sqlite')\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"Database {db_name} not found.\")\n",
    "        return False\n",
    "\n",
    "    generated_results = execute_query(db_path, generated_query)\n",
    "    original_results = execute_query(db_path, original_query)\n",
    "\n",
    "    # print(generated_results)\n",
    "    # print(original_results)\n",
    "\n",
    "    gen_list = convert_to_list(generated_results)\n",
    "    orig_list = convert_to_list(original_results)\n",
    "\n",
    "    print(gen_list)\n",
    "    print(orig_list)\n",
    "\n",
    "    return Counter(gen_list) == Counter(orig_list)   \n",
    "\n",
    "def extract_sql_query(response):\n",
    "    start = response.find(\"```sqlite\")\n",
    "    flag=0\n",
    "    if (start==-1):\n",
    "        flag=1\n",
    "        start = response.find(\"```sql\")\n",
    "    end = response.find(\"```\", start + 1)\n",
    "    if start == -1 or end == -1:\n",
    "        return \"\"\n",
    "    sql_query=\"\"\n",
    "    if flag==1: sql_query = response[start + 6:end].strip()  # Extract the query between ```sql and ```\n",
    "    else: sql_query = response[start + 9:end].strip()\n",
    "    return sql_query\n",
    "\n",
    "def table_desc_extractor(table_info, table_description):\n",
    "    table_extract = {}\n",
    "    for table in table_info:\n",
    "        table_name = table[0]\n",
    "        table_col = str(table[1])\n",
    "        table_row = str(table[2])\n",
    "        # Check if table_name exists in table_description and is not None, else use a default value\n",
    "        table_desc = table_description.get(table_name, \"No description\") if table_description.get(table_name) is not None else \"No description\"\n",
    "        table_extract[table_name] ={\n",
    "            \"table_description\": table_desc,\n",
    "            \"table_columns\": table_col,\n",
    "            \"table_first_row\": table_row\n",
    "        }\n",
    "    return table_extract\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise cross prompt variiables (DANGER: DO NOT PRESS)\n",
    "totalQueries=0\n",
    "correctAns=0\n",
    "notCorrectAns=0\n",
    "file_path = 'F:/OneDrive/Desktop/Study/NLP_ResearchProject/Project/incorrectGeminiLog.txt'\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    pass\n",
    "file_path = 'F:/OneDrive/Desktop/Study/NLP_ResearchProject/Project/geminiLog.txt'\n",
    "with open(file_path, 'w') as file:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totalQueries setter\n",
    "# totalQueries=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(totalQueries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalQueries=191\n",
    "correctAns=123\n",
    "notCorrectAns=68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    numerator=0\n",
    "    for i in range(len(v1)):\n",
    "        numerator+=(v1[i]*v2[i])\n",
    "    if sum(v1)==0 or sum(v2)==0:\n",
    "        return -1\n",
    "    numerator/=math.sqrt(sum(v1))\n",
    "    numerator/=math.sqrt(sum(v2))\n",
    "    return numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=0\n",
    "\n",
    "for dbName, dbSchema in schema_array.items():\n",
    "    if dbName not in databases: continue\n",
    "    if 'tables' not in dbSchema: continue\n",
    "    num_questions=len(databases[dbName]['question'])\n",
    "    num_tables=len(dbSchema['tables'])\n",
    "    if num_tables<8 or num_questions<25: continue\n",
    "    total+=num_questions\n",
    "    # print(dbName)\n",
    "    # print(f\"{len(dbSchema['tables'])}, {len(databases[dbName]['question'])}\")\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_table_extract = {}\n",
    "count = 0\n",
    "model_used = 'gemini'\n",
    "database_table_descrition = {}\n",
    "for folder, data in schema_array.items():\n",
    "    if folder in database_table_extract:\n",
    "        continue \n",
    "    # if folder != 'tracking_orders': continue\n",
    "    if folder not in databases: continue\n",
    "    if folder not in ['world_1', 'voter_1', 'twitter_1', 'soccer_1', 'small_bank_1', 'school_player', 'icfp', 'gymnast', 'flight_4', 'epinions_1', 'company_1']:\n",
    "        continue\n",
    "    # if 'tables' not in data: continue\n",
    "    print(f\"Folder: {folder}\")\n",
    "    num_questions=len(databases[folder]['question'])\n",
    "    num_tables=len(data['table_info'])\n",
    "    schema = data.get('schema', {})\n",
    "    # print(f\"Schema: {schema}\")\n",
    "    \n",
    "    table_info = data.get('table_info', [])\n",
    "    tables_used=json.dumps(schema)\n",
    "    table_extraction_prompt = \"Here is the schema of the database\" + tables_used + \"\\n\"\n",
    "    table_extraction_prompt2 = '''\n",
    "    Give a detailed description of each table in the database. I have provided you the schema which contains the column names. I have also provided sample data, which is essentially the first row of the table, for better understanding. Use all the information to understand the table deeply, and provid information about it. The information should include what each column of the table contains, as well. Describe in english what each column is storing according to you. We will be using the information you provide for extracting queries that use this table. Also, all information should be in the fomr of a single paragraph. The response should be # Table table_name table_description ! . A sample response may look like: \n",
    "    #Table employees\n",
    "    Stores infomation regarding all the employees in the company. The column e_id is the employee ID of each employee, which is unique to each employee.\n",
    "    !\n",
    "    \\n\n",
    "    '''\n",
    "    table_prompt = table_extraction_prompt + table_extraction_prompt2\n",
    "    response = printResponse(table_prompt,model_used)\n",
    "    with open('./geminiLog.txt', 'a') as f:\n",
    "        f.write(f\"\\nResponse:\\n{response}\\n\\n\")\n",
    "    table_description = extract_table_descriptions(response)\n",
    "    print(table_description)\n",
    "\n",
    "    database_table_descrition[folder] = table_description\n",
    "    table_extract = table_desc_extractor(table_info, table_description)\n",
    "\n",
    "    database_table_extract[folder] = table_extract\n",
    "\n",
    "    # for table in table_info:\n",
    "    #     table_name, columns, first_row = table\n",
    "    #     print(f\"  Table Name: {table_name}\")\n",
    "    #     print(f\"  Columns: {columns}\")\n",
    "    #     print(f\"  First Row: {first_row}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(database_table_extract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('database_table_extract.json', 'a') as json_file:\n",
    "    json_file.write(json.dumps(database_table_descrition, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_table_extract = {}\n",
    "count = 0\n",
    "model_used = 'gemini'\n",
    "database_table_descrition = {}\n",
    "for folder, data in schema_array.items():\n",
    "    if folder == 'soccer_1':\n",
    "        continue\n",
    "    if folder in past_table_description:\n",
    "        continue\n",
    "    if folder in database_table_extract:\n",
    "        continue \n",
    "    # if folder != 'tracking_orders': continue\n",
    "    if folder not in databases: continue\n",
    "    # if 'tables' not in data: continue\n",
    "    print(f\"Folder: {folder}\")\n",
    "    num_questions=len(databases[folder]['question'])\n",
    "    num_tables=len(data['table_info'])\n",
    "    schema = data.get('schema', {})\n",
    "    # print(f\"Schema: {schema}\")\n",
    "    \n",
    "    table_info = data.get('table_info', [])\n",
    "    tables_used=json.dumps(schema)\n",
    "    table_extraction_prompt = \"Here is the schema of the database\" + tables_used + \"\\n\"\n",
    "    table_extraction_prompt2 = '''\n",
    "    Give a detailed description of each table in the database. I have provided you the schema which contains the column names. I have also provided sample data, which is essentially the first row of the table, for better understanding. Use all the information to understand the table deeply, and provid information about it. The information should include what each column of the table contains, as well. Describe in english what each column is storing according to you. We will be using the information you provide for extracting queries that use this table. Also, all information should be in the fomr of a single paragraph. The response should be # Table table_name table_description ! . A sample response may look like: \n",
    "    #Table employees\n",
    "    Stores infomation regarding all the employees in the company. The column e_id is the employee ID of each employee, which is unique to each employee.\n",
    "    !\n",
    "    \\n\n",
    "    '''\n",
    "    table_prompt = table_extraction_prompt + table_extraction_prompt2\n",
    "    response = printResponse(table_prompt,model_used)\n",
    "    with open('./geminiLog.txt', 'a') as f:\n",
    "        f.write(f\"\\nResponse:\\n{response}\\n\\n\")\n",
    "    table_description = extract_table_descriptions(response)\n",
    "    print(table_description)\n",
    "\n",
    "    database_table_descrition[folder] = table_description\n",
    "    table_extract = table_desc_extractor(table_info, table_description)\n",
    "\n",
    "    database_table_extract[folder] = table_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('database_table_extract.json', 'a') as json_file:\n",
    "    json_file.write(json.dumps(database_table_descrition, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('database_table_extract.json', 'r') as json_file:\n",
    "    past_table_description = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(past_table_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_table_extract = {}\n",
    "\n",
    "for folder, data in schema_array.items():\n",
    "    if folder not in past_table_description:\n",
    "        continue\n",
    "    table_description = past_table_description[folder]\n",
    "    table_info = data.get('table_info', [])\n",
    "    table_extract = table_desc_extractor(table_info, table_description)\n",
    "\n",
    "    database_table_extract[folder] = table_extract\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder, values in database_table_extract.items():\n",
    "    print(f\"Folder: {folder}\")\n",
    "    for table_name, table_info in values.items():\n",
    "        print(f\"  Table Name: {table_name}\")\n",
    "        print(f\"  Table Info: {table_info}\")\n",
    "    print(len(database_table_extract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for folder, tables in database_table_extract.items():\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised learning\n",
    "model_used = 'gemini'\n",
    "threshold = 0.5\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "db_table_extraction_list = {}\n",
    "total_num_correct = 0\n",
    "total_num_incorrect = 0\n",
    "\n",
    "for folder, tables in database_table_extract.items():\n",
    "    print(f\"Folder: {folder}\")\n",
    "    num_questions = len(databases[folder]['question'])\n",
    "    num_correct = 0\n",
    "    num_incorrect = 0\n",
    "\n",
    "    for i in range(num_questions):\n",
    "        question = databases[folder]['question'][i]\n",
    "        question_embedding = embedder.encode(question, convert_to_tensor=True)\n",
    "        table_similarities = {}\n",
    "        for table_name, table_info in tables.items():\n",
    "            table_description = table_info['table_description']\n",
    "            table_description_embedding = embedder.encode(table_description, convert_to_tensor=True)\n",
    "            similarity = util.pytorch_cos_sim(question_embedding, table_description_embedding)\n",
    "            table_similarities[table_name.lower()] = similarity.item()\n",
    "        \n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Table Similarities: {table_similarities}\")\n",
    "        \n",
    "\n",
    "        num_elements = len(table_similarities)\n",
    "        flag = True\n",
    "        if num_elements <= 4:\n",
    "            flag = False\n",
    "\n",
    "        \n",
    "        try:\n",
    "            average_score = sum(table_similarities.values()) / len(table_similarities)\n",
    "        except ZeroDivisionError:\n",
    "            average_score = 0  # or any other default value or action\n",
    "        selected_tables = []\n",
    "        if flag:\n",
    "            selected_tables = [table_name for table_name, score in table_similarities.items() if score > average_score]\n",
    "        else :\n",
    "            selected_tables = [table_name for table_name, score in table_similarities.items()]\n",
    "        print(f\"Selected Tables: {selected_tables}\")\n",
    "        \n",
    "        table_list = databases[folder]['tables'][i]\n",
    "        query = databases[folder]['query'][i]\n",
    "        print(f\"Table List: {table_list}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        \n",
    "        # Check if all tables in table_list are present in selected_tables\n",
    "        if all(table in selected_tables for table in table_list):\n",
    "            print(\"Correct\")\n",
    "            num_correct += 1\n",
    "            total_num_correct += 1\n",
    "        else:\n",
    "            print(\"Incorrect\")\n",
    "            num_incorrect += 1\n",
    "            total_num_incorrect += 1\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    percent = (num_correct / num_questions) * 100\n",
    "    print(f\"{folder} has this much accuracy {percent}\")\n",
    "    db_table_extraction_list[folder] = {\n",
    "        \"Accuracy\": percent,\n",
    "        \"Correct\": num_correct,\n",
    "        \"Incorrect\": num_incorrect\n",
    "    }\n",
    "    print(\"\\n\")\n",
    "\n",
    "total_percent = (total_num_correct / (total_num_correct + total_num_incorrect)) * 100\n",
    "\n",
    "print(f\"Total Percent Accuracy: {total_percent}\")\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "# Select the tables with similarity scores above the average score / 75% quartile\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder, accuracy in db_table_extraction_list.items():\n",
    "    print(f\"Folder: {folder}\")\n",
    "    print(f\"Accuracy: {accuracy['Accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"table_extraction_percentAccuracy.json\", \"w\") as f:\n",
    "    json.dump(db_table_extraction_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_table_extraction_percent_accuracy = {}\n",
    "easy_table_extraction_percent_accuracy = {}\n",
    "\n",
    "for folder, accuracy in db_table_extraction_list.items():\n",
    "    if folder in hard_dataset:\n",
    "        hard_table_extraction_percent_accuracy[folder] = accuracy\n",
    "    else:\n",
    "        easy_table_extraction_percent_accuracy[folder] = accuracy\n",
    "\n",
    "with open(\"hard_table_extraction_percent_accuracy.json\", \"w\") as f:\n",
    "    json.dump(hard_table_extraction_percent_accuracy, f, indent=4)\n",
    "with open(\"easy_table_extraction_percent_accuracy.json\", \"w\") as f:\n",
    "    json.dump(easy_table_extraction_percent_accuracy, f, indent=4)\n",
    "\n",
    "hard_num_correct = 0\n",
    "hard_num_incorrect = 0\n",
    "hard_percent = 0\n",
    "\n",
    "for folder, accuracy in hard_table_extraction_percent_accuracy.items():\n",
    "    hard_num_correct += accuracy['Correct']\n",
    "    hard_num_incorrect += accuracy['Incorrect']\n",
    "hard_percent = (hard_num_correct / (hard_num_correct + hard_num_incorrect)) * 100\n",
    "\n",
    "easy_num_correct = 0\n",
    "easy_num_incorrect = 0\n",
    "easy_percent = 0\n",
    "\n",
    "for folder, accuracy in easy_table_extraction_percent_accuracy.items():\n",
    "    easy_num_correct += accuracy['Correct']\n",
    "    easy_num_incorrect += accuracy['Incorrect']\n",
    "easy_percent = (easy_num_correct / (easy_num_correct + easy_num_incorrect)) * 100\n",
    "hard_size = len(hard_table_extraction_percent_accuracy)\n",
    "easy_size = len(easy_table_extraction_percent_accuracy)\n",
    "percent = {\n",
    "    \"Hard\": hard_percent,\n",
    "    \"Easy\": easy_percent,\n",
    "    \"total\": total_percent,\n",
    "    \"Hard Size\": hard_size,\n",
    "    \"Easy Size\": easy_size,\n",
    "    \"hard_num_correct\": hard_num_correct,\n",
    "    \"hard_num_incorrect\": hard_num_incorrect,\n",
    "    \"easy_num_correct\": easy_num_correct,\n",
    "    \"easy_num_incorrect\": easy_num_incorrect\n",
    "}\n",
    "\n",
    "with open(\"table_extraction_percent.json\", \"w\") as f:\n",
    "    json.dump(percent, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used='gemini'\n",
    "newInstTot=0\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")        \n",
    "\n",
    "for dbName, dbSchema in schema_array.items():\n",
    "\n",
    "    if dbName not in databases: continue\n",
    "    if 'tables' not in dbSchema: continue\n",
    "    num_questions=len(databases[dbName]['question'])\n",
    "    num_tables=len(dbSchema['tables'])\n",
    "\n",
    "    #filtering out heavy databases\n",
    "    if num_tables<8 or num_questions<25: continue\n",
    "\n",
    "    print(dbName)\n",
    "\n",
    "    dbTables=[]\n",
    "    for table in dbSchema[\"tables\"]:\n",
    "        dbTables.append(table[\"name\"].lower())\n",
    "\n",
    "    for i in range(len(databases[dbName]['question'])):\n",
    "        # print(f\"{totalQueries}, {newInstTot}\")\n",
    "        newInstTot+=1\n",
    "        if (totalQueries>=(newInstTot)):\n",
    "            continue\n",
    "\n",
    "        # print(f\"{totalQueries}, {newInstTot}\")\n",
    "        tables_used=\"\"\n",
    "\n",
    "        # Iterate through dbNames\n",
    "\n",
    "        for tname in databases[dbName]['tables'][i]:\n",
    "            for tables in dbSchema[\"tables\"]:\n",
    "                if tables[\"name\"].lower() ==tname.lower() :\n",
    "                    tables_used += json.dumps(tables) + \"\\n\"\n",
    "\n",
    "\n",
    "        #shots chosen dynamically\n",
    "        queryVector=[0]*len(dbTables)\n",
    "        for tname in databases[dbName]['tables'][i]:\n",
    "            if tname.lower() in dbTables:\n",
    "                queryVector[dbTables.index(tname.lower())]=1\n",
    "        \n",
    "        shots=[]\n",
    "\n",
    "        print(dbTables)\n",
    "        # print(databases[dbName]['question'][i])\n",
    "        print(databases[dbName]['question'][i])\n",
    "        print(queryVector)\n",
    "\n",
    "        quer_embedding = embedder.encode(databases[dbName]['question'][i], convert_to_tensor=True)\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range(len(databases[dbName]['question'])):\n",
    "            if abs(j - i) > 1:\n",
    "                shotVector=[0]*len(dbTables)\n",
    "                for tname in databases[dbName]['tables'][j]:\n",
    "                    if tname.lower() in dbTables:\n",
    "                        shot_embedding = embedder.encode(databases[dbName]['question'][j], convert_to_tensor=True)\n",
    "                        shotVector[dbTables.index(tname.lower())]=1\n",
    "                shots.append([embedder.similarity(quer_embedding,shot_embedding)[0],databases[dbName]['question'][j],databases[dbName]['query'][j]])\n",
    "\n",
    "        shots.sort(reverse=True)\n",
    "\n",
    "        for items in shots:\n",
    "            print(items[0])\n",
    "            print(items[1])\n",
    "            print(items[2])\n",
    "\n",
    "        dynamicPrompt=\"Here are some examples:\\n\"\n",
    "\n",
    "        for j in range(min(3,len(shots))):\n",
    "            dynamicPrompt+=f\"Example {j+1}:\\n\\nQuestion:\\n{shots[j][1]}\\n\\nSQL Query:\\n{shots[j][2]}\\n\\n\"\n",
    "\n",
    "\n",
    "        #prompts used\n",
    "        tables_used=json.dumps(schema_array[dbName])\n",
    "        initialPrompt=f\"I will feed you schema of a database, store it and then use it to answer the question I will ask related to the database.\\n\"\n",
    "        tablesPrompt = \"Following is the schema of tables you can use to write the SQL Query.\" + \"\\n\" + tables_used + \"\\n\"\n",
    "        table_extraction_prompt = \"Give a one line description of each table in the database. Start the description with a '#', and end it with a '!'.\\n\"\n",
    "        infoPrompt = \"we are using sqlite as the tool for running the queries. Keep syntax related to it in mind, and provide code accordingly. Dont forget the semicolons wherever needed.\"\n",
    "        columnNamePrompt = \"Be careful with the names of columns. Use precise column names, since changing them (for example making uppercase to lowercase) may lead to error. Also enclose the column names in double quotes to avoid any clashes with reserved keywords.\\n\"\n",
    "        examplePrompt = '''\n",
    "        Avoid using = if possible, in situations like in this query:\n",
    "                            SELECT\n",
    "                            m.Location,\n",
    "                            a.Aircraft\n",
    "                            FROM `match` AS m\n",
    "                            JOIN aircraft AS a\n",
    "                            ON m.Winning_Aircraft = a.Aircraft_ID\n",
    "                            WHERE\n",
    "                            m.Round = (\n",
    "                                SELECT\n",
    "                                `Round`\n",
    "                                FROM `match`\n",
    "                                ORDER BY\n",
    "                                Fastest_Qualifying\n",
    "                                LIMIT 1\n",
    "                            );\n",
    "                            Here since = is used, m.Round is limited to one row which is not correct.\n",
    "                            Also, always check datatypes to ensure that u are understanding the information a column represents correctly. For example, sometimes a column with say name pilot may actually represent its id and not its name.\n",
    "                            To help with this, first state your understanding of what the columns actually represent, then walk through the logic for how you are writing the particular query (a stepwise explanation), and then print the final query.\n",
    "                            \n",
    "                            You can also use joins to extract information. For example:\n",
    "                            Question: What are the last names and ages of the students who are allergic to milk and cat?\n",
    "                            Tables: Student, Has_Allergy\n",
    "                            SQL Query:\n",
    "                                SELECT s.LName, s.Age\n",
    "                                FROM Student s\n",
    "                                JOIN Has_Allergy ha1 ON s.StuID = ha1.StuID\n",
    "                                JOIN Has_Allergy ha2 ON s.StuID = ha2.StuID\n",
    "                                WHERE ha1.Allergy = 'Milk' AND ha2.Allergy = 'Cat';\n",
    "                            Notice how I have joined 3 tables, 2 of which are same. Essentially any table can be joined with any other under suitable constraints.\n",
    "\n",
    "        Also take care of string type columns. Don't confuse singular with plural, for example, egg with eggs. Use the precise string in queries.\n",
    "\n",
    "        When using AND and OR operators together, use parentheses to ensure the correct logical grouping of conditions. For example:\n",
    "        Question: How many female students are allergic to milk or eggs?\n",
    "        Tables: Student, Has_Allergy\n",
    "        Incorrect SQL Query:\n",
    "            SELECT count(*) \n",
    "            FROM has_allergy AS T1 \n",
    "            JOIN Student AS T2 ON T1.StuID = T2.StuID \n",
    "            WHERE T2.sex = \"F\" AND T1.allergy = \"Milk\" OR T1.allergy = \"Eggs\";\n",
    "\n",
    "        Correct SQL Query:\n",
    "            SELECT count(*) \n",
    "            FROM has_allergy AS T1 \n",
    "            JOIN Student AS T2 ON T1.StuID = T2.StuID \n",
    "            WHERE T2.sex = \"F\" AND (T1.allergy = \"Milk\" OR T1.allergy = \"Eggs\");\n",
    "\n",
    "        Notice the use of parentheses to group the OR conditions properly. Always use parentheses to avoid logical errors when combining AND and OR operators.\n",
    "\n",
    "        Also, when there is a column name, say X, present in more than one tables, say both T1 and T2, be very specific of the column you are using in the sql query. So, if u want to use the column from T1,\n",
    "        be sure to use T1.X instead of simply X. This helps avoid the ambiguous column error.   \n",
    "\n",
    "        '''\n",
    "        chainOfThoughtPrompt=\"Understand what each column and table mean. State what you understand about the tabel and their relatons. Also state logical steps in between as to how you are constructing the final SQL query.\"\n",
    "        questionPrompt=\"\\nHere is the question part, i.e., the query on the database above, explained in english, for which the corresponding SQL query code is needed.: \\n\\n\\n\" + databases[dbName]['question'][i] + \"\\n\\n\\n\" +  \"\\n\" + \"Provide the SQL query at the end of the response.\\n\"\n",
    "\n",
    "        prompt=initialPrompt+tablesPrompt+table_extraction_prompt+infoPrompt+columnNamePrompt+examplePrompt+dynamicPrompt+chainOfThoughtPrompt+questionPrompt\n",
    "\n",
    "        #get response from LLM\n",
    "        response=printResponse(prompt,model_used)\n",
    "        \n",
    "\n",
    "        #get og and gen queries\n",
    "        generated_query = extract_sql_query(response)\n",
    "        original_query = databases[dbName]['query'][i]\n",
    "        if not original_query.endswith(';'):\n",
    "            original_query+=';'\n",
    "\n",
    "        #compare og and gen queries\n",
    "        isSame=compare_queries(dbName, db_folder_path, generated_query, original_query)\n",
    "\n",
    "        #logging\n",
    "        print(f\"Q{totalQueries+1}:\\n\") \n",
    "        if isSame==False:\n",
    "            print(\"The queries do not match.\\n\")\n",
    "            notCorrectAns+=1\n",
    "\n",
    "            #logging in incorrectGeminiLog.txt\n",
    "            with open('./incorrectGeminiLog.txt', 'a') as f:\n",
    "                f.write(f\"Q{totalQueries+1}:\\n\")\n",
    "                f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "                # f.write(f\"LLM_Input:\\n{prompt}\\n\")\n",
    "                f.write(f\"\\n\\n\\ncosine_similarity: {shots[0][0]} {shots[1][0]} {shots[2][0]}\\n\\n\\n\")\n",
    "                f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "                f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "                f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "                f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "                f.write(f\"\\n\\n\\n\")\n",
    "\n",
    "        else:\n",
    "            print(\"The queries match.\\n\")\n",
    "            correctAns+=1\n",
    "        totalQueries+=1\n",
    "\n",
    "        #logging in geminiLog.txt\n",
    "        with open('./geminiLog.txt', 'a') as f:\n",
    "            f.write(f\"Q{totalQueries}:\\n\")\n",
    "            f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "            # f.write(f\"LLM_Input:\\n{prompt}\\n\")\n",
    "            f.write(f\"\\n\\n\\ncosine_similarity: {shots[0][0]} {shots[1][0]} {shots[2][0]}\\n\\n\\n\")\n",
    "            f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "            f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "            f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "            f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "            f.write(f\"Total Queries: {totalQueries}, Correct Answers: {correctAns}, Incorrect Answers: {notCorrectAns}\")\n",
    "            f.write(f\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalQueriesNG=0\n",
    "correctAnsNG=0\n",
    "notCorrectAnsNG=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schema_array['browser_web']['tables'][0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalQueriesNG=0\n",
    "correctAnsNG=0\n",
    "notCorrectAns=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used='gemini'\n",
    "newInstTot=0\n",
    "for dbName, dbSchema in schema_array.items():\n",
    "    \n",
    "    if dbName not in databases:\n",
    "        continue\n",
    "\n",
    "    print(dbName)\n",
    "\n",
    "    for i in range(len(databases[dbName]['question'])):\n",
    "        # print(f\"{totalQueriesNG}, {newInstTot}\")\n",
    "        newInstTot+=1\n",
    "        if (totalQueriesNG>=(newInstTot)):\n",
    "            continue\n",
    "\n",
    "        # print(f\"{totalQueriesNG}, {newInstTot}\")\n",
    "        tables_used=\"\"\n",
    "\n",
    "        # Iterate through dbNames\n",
    "\n",
    "        for tname in databases[dbName]['tables'][i]:\n",
    "            for tables in dbSchema[\"tables\"]:\n",
    "                if tables[\"name\"].lower() ==tname.lower() :\n",
    "                    tables_used += json.dumps(tables) + \"\\n\"\n",
    "\n",
    "        \n",
    "\n",
    "        #prompts used\n",
    "        tables_used=json.dumps(schema_array[dbName])\n",
    "        initialPrompt=f\"I will feed you schema of a database, store it and then use it to answer the question I will ask related to the database.\\n\"\n",
    "        tablesPrompt = \"Following is the schema of tables you can use to write the SQL Query.\" + \"\\n\\n\" +tables_used + \"\\n\\n\"\n",
    "        infoPrompt = \"we are using sqlite as the tool for running the queries. Keep syntax related to it in mind, and provide code accordingly. Dont forget the semicolons wherever needed.\"\n",
    "        columnNamePrompt = \"Be careful with the names of columns. Use precise column names, since changing them (for example making uppercase to lowercase) may lead to error. Also enclose the column names in double quotes to avoid any clashes with reserved keywords.\\n\"\n",
    "        examplePrompt = '''\n",
    "        Avoid using = if possible, in situations like in this query:\n",
    "                            SELECT\n",
    "                            m.Location,\n",
    "                            a.Aircraft\n",
    "                            FROM `match` AS m\n",
    "                            JOIN aircraft AS a\n",
    "                            ON m.Winning_Aircraft = a.Aircraft_ID\n",
    "                            WHERE\n",
    "                            m.Round = (\n",
    "                                SELECT\n",
    "                                `Round`\n",
    "                                FROM `match`\n",
    "                                ORDER BY\n",
    "                                Fastest_Qualifying\n",
    "                                LIMIT 1\n",
    "                            );\n",
    "                            Here since = is used, m.Round is limited to one row which is not correct.\n",
    "                            Also, always check datatypes to ensure that u are understanding the information a column represents correctly. For example, sometimes a column with say name pilot may actually represent its id and not its name.\n",
    "                            To help with this, first state your understanding of what the columns actually represent, then walk through the logic for how you are writing the particular query (a stepwise explanation), and then print the final query.\n",
    "                            \n",
    "                            You can also use joins to extract information. For example:\n",
    "                            Question: What are the last names and ages of the students who are allergic to milk and cat?\n",
    "                            Tables: Student, Has_Allergy\n",
    "                            SQL Query:\n",
    "                                SELECT s.LName, s.Age\n",
    "                                FROM Student s\n",
    "                                JOIN Has_Allergy ha1 ON s.StuID = ha1.StuID\n",
    "                                JOIN Has_Allergy ha2 ON s.StuID = ha2.StuID\n",
    "                                WHERE ha1.Allergy = 'Milk' AND ha2.Allergy = 'Cat';\n",
    "                            Notice how I have joined 3 tables, 2 of which are same. Essentially any table can be joined with any other under suitable constraints.\n",
    "\n",
    "        Also take care of string type columns. Don't confuse singular with plural, for example, egg with eggs. Use the precise string in queries.\n",
    "\n",
    "        When using AND and OR operators together, use parentheses to ensure the correct logical grouping of conditions. For example:\n",
    "        Question: How many female students are allergic to milk or eggs?\n",
    "        Tables: Student, Has_Allergy\n",
    "        Incorrect SQL Query:\n",
    "            SELECT count(*) \n",
    "            FROM has_allergy AS T1 \n",
    "            JOIN Student AS T2 ON T1.StuID = T2.StuID \n",
    "            WHERE T2.sex = \"F\" AND T1.allergy = \"Milk\" OR T1.allergy = \"Eggs\";\n",
    "\n",
    "        Correct SQL Query:\n",
    "            SELECT count(*) \n",
    "            FROM has_allergy AS T1 \n",
    "            JOIN Student AS T2 ON T1.StuID = T2.StuID \n",
    "            WHERE T2.sex = \"F\" AND (T1.allergy = \"Milk\" OR T1.allergy = \"Eggs\");\n",
    "\n",
    "        Notice the use of parentheses to group the OR conditions properly. Always use parentheses to avoid logical errors when combining AND and OR operators.\n",
    "\n",
    "        Also, when there is a column name, say X, present in more than one tables, say both T1 and T2, be very specific of the column you are using in the sql query. So, if u want to use the column from T1,\n",
    "        be sure to use T1.X instead of simply X. This helps avoid the ambiguous column error.   \n",
    "\n",
    "        '''\n",
    "        chainOfThoughtPrompt=\"Understand what each column and table mean. State what you understand about the tabel and their relatons. Also state logical steps in between as to how you are constructing the final SQL query.\"\n",
    "        questionPrompt=\"\\nHere is the question part, i.e., the query on the database above, explained in english, for which the corresponding SQL query code is needed.: \\n\\n\" + databases[dbName]['question'][i] + \"\\n\\n\" +  \"\\n\" + \"Provide the SQL query at the end of the response.\\n\"\n",
    "\n",
    "        prompt=initialPrompt+tablesPrompt+infoPrompt+columnNamePrompt+examplePrompt+chainOfThoughtPrompt+questionPrompt\n",
    "\n",
    "        #get response from LLM\n",
    "        response=printResponse(prompt,model_used)\n",
    "\n",
    "        #get og and gen queries\n",
    "        generated_query = extract_sql_query(response)\n",
    "        original_query = databases[dbName]['query'][i]\n",
    "        if not original_query.endswith(';'):\n",
    "            original_query+=';'\n",
    "\n",
    "        #compare og and gen queries\n",
    "        isSame=compare_queries(dbName, db_folder_path, generated_query, original_query)\n",
    "\n",
    "        #logging\n",
    "        print(f\"Q{totalQueriesNG+1}:\\n\") \n",
    "        if isSame==False:\n",
    "            print(\"The queries do not match.\\n\")\n",
    "            notCorrectAnsNG+=1\n",
    "\n",
    "            #logging in incorrectGeminiLog.txt\n",
    "            with open('./incorrectGeminiLogNoGolden.txt', 'a') as f:\n",
    "                f.write(f\"Q{totalQueriesNG+1}:\\n\")\n",
    "                f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "                f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "                f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "                f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "                f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "                f.write(f\"\\n\\n\\n\")\n",
    "\n",
    "        else:\n",
    "            print(\"The queries match.\\n\")\n",
    "            correctAnsNG+=1\n",
    "        totalQueriesNG+=1\n",
    "\n",
    "        #logging in geminiLog.txt\n",
    "        with open('./geminiLogNoGolden.txt', 'a') as f:\n",
    "            f.write(f\"Q{totalQueriesNG}:\\n\")\n",
    "            f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "            f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "            f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "            f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "            f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "            f.write(f\"Total Queries: {totalQueriesNG}, Correct Answers: {correctAnsNG}, Incorrect Answers: {notCorrectAnsNG}\")\n",
    "            f.write(f\"\\n\\n\\n\")        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
