{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "import sqlite3\n",
    "import logging\n",
    "import mysql.connector\n",
    "from collections import Counter\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv('.env')\n",
    "api_key_gpt= os.getenv('CHATGPT_API_KEY')\n",
    "client = OpenAI(\n",
    "  api_key=api_key_gpt,\n",
    ")\n",
    "\n",
    "def create_batch_file(prompts, max_tokens=50):\n",
    "    custom_requests = []\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        custom_request = {\n",
    "            \"custom_id\": f\"request-{i+1}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o-mini\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                \"max_tokens\": max_tokens\n",
    "            }\n",
    "        }\n",
    "        custom_requests.append(custom_request)\n",
    "\n",
    "    input_file = \"input_prompt_file.jsonl\"\n",
    "\n",
    "    with open(input_file, \"w\") as file:\n",
    "        for item in custom_requests:\n",
    "            file.write(json.dumps(item))\n",
    "            file.write(\"\\n\")\n",
    "    print(\"Batch input file created successfully.\")\n",
    "\n",
    "def process_batch_file(input_file):\n",
    "    input_file_id = client.files.create(\n",
    "        file=open(input_file, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    ).id\n",
    "\n",
    "    batch = client.batches.create(\n",
    "        input_file_id=input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": \"nightly eval job\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    batch_id = batch.id  # Capture the batch ID\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            batch_status = client.batches.retrieve(batch_id)\n",
    "            print(f\"Batch file processing status: {batch_status.status}\")\n",
    "            \n",
    "            if batch_status.status in [\"completed\", \"failed\", \"expired\"]:\n",
    "                break\n",
    "            time.sleep(10)  # Wait for 10 seconds before checking again\n",
    "\n",
    "        if batch_status.status == \"completed\":\n",
    "            print(\"Batch file processing completed.\")\n",
    "            \n",
    "            # Retrieve the file content\n",
    "            file_response = client.files.content(batch_status.result_file_id)\n",
    "            file_content = file_response.read().decode('utf-8')\n",
    "            return file_content\n",
    "        else:\n",
    "            print(f\"Batch file processing ended with status: {batch_status.status}\")\n",
    "            return None\n",
    "    except openai.error.OpenAIError as e:\n",
    "        print(f\"An error occurred while retrieving the batch status: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "prompts = [\"What is the capital of France?\", \"What is the capital of Italy?\"]\n",
    "create_batch_file(prompts)\n",
    "response_content = process_batch_file(\"input_prompt_file.jsonl\")\n",
    "if response_content:\n",
    "    responses = response_content.splitlines()\n",
    "    for response in responses:\n",
    "        response_json = json.loads(response)\n",
    "        print(json.dumps(response_json, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up LLMs\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#gpt\n",
    "api_key_gpt=os.getenv('CHATGPT_API_KEY')\n",
    "client = OpenAI(\n",
    "  api_key=api_key_gpt,\n",
    ")\n",
    "\n",
    "#gemini\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "modelGemini=genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "\n",
    "#llama\n",
    "api_key_llama=os.getenv(\"LLAMA_API_KEY\")\n",
    "client = OpenAI(\n",
    "    api_key = api_key_llama,\n",
    "    base_url = \"https://api.llama-api.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResponse(prompt,llm):\n",
    "    # print(f\"User:\\n{prompt}\\n\\n\")\n",
    "    if llm=='gpt':\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ]            \n",
    "        )\n",
    "        response=chat_completion.choices[0].message.content\n",
    "        # print(f\"LLM:\\n{response}\\n\\n\")\n",
    "        return response\n",
    "    elif llm=='gemini':\n",
    "        time.sleep(18)      #gemini response limit mitigation,\n",
    "        response = modelGemini.generate_content(prompt)\n",
    "        # print(f\"LLM:\\n{response.text}\\n\\n\")\n",
    "        return response.text\n",
    "    elif llm=='llama':\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-13b-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        response=response.choices[0].message.content\n",
    "        # print(f\"LLM:\\n{response}\\n\\n\")\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "#gpt\n",
    "api_key_gpt=os.getenv('CHATGPT_API_KEY')\n",
    "client = OpenAI(\n",
    "  api_key=api_key_gpt,\n",
    ")\n",
    "\n",
    "def printResponse(prompt,llm):\n",
    "    # print(f\"User:\\n{prompt}\\n\\n\")\n",
    "    if llm=='gpt':\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ]            \n",
    "        )\n",
    "        response=chat_completion.choices[0].message.content\n",
    "        # print(f\"LLM:\\n{response}\\n\\n\")\n",
    "        return response\n",
    "    elif llm=='gemini':\n",
    "        time.sleep(18)      #gemini response limit mitigation,\n",
    "        response = modelGemini.generate_content(prompt)\n",
    "        # print(f\"LLM:\\n{response.text}\\n\\n\")\n",
    "        return response.text\n",
    "    elif llm=='llama':\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-13b-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        response=response.choices[0].message.content\n",
    "        # print(f\"LLM:\\n{response}\\n\\n\")\n",
    "        return response\n",
    "    \n",
    "def batch_response(batch_input_file):\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "        \"description\": \"nightly eval job\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    batch_status = client.batches.retrieve(\"batch_abc123\")\n",
    "\n",
    "    # Check if the batch is completed\n",
    "    if batch_status['status'] == 'completed':\n",
    "        # Retrieve the file content\n",
    "        file_response = client.files.content(\"file-xyz123\")\n",
    "        print(file_response.text)\n",
    "    else:\n",
    "        print(\"Batch is not yet completed. Please try again later.\")\n",
    "\n",
    "    file_response = client.files.content(\"file-xyz123\")\n",
    "    print(file_response.text)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDbSchemaMapping(dbFolderPath):\n",
    "    count=0\n",
    "    schema_array = {}\n",
    "    for folder in os.listdir(dbFolderPath):\n",
    "        count+=1\n",
    "        folder_path = os.path.join('./spider/database', folder)\n",
    "        if os.path.exists(folder_path):\n",
    "            flag=0\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.json'):\n",
    "                    flag=1\n",
    "                    json_file_path = os.path.join(folder_path, file_name)\n",
    "                    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                        schema_array[folder] = json.load(file)\n",
    "            if flag==0:\n",
    "                print(folder_path)\n",
    "    print(count)\n",
    "    return schema_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nqlex_data_path=\"selectedTables/selected_tables.json\"\n",
    "with open(nqlex_data_path,\"r\") as f:\n",
    "        nlqex_data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlqex_data['activity_1']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tableJsonPath,cleanDataPath):\n",
    "\n",
    "    with open(tableJsonPath,\"r\") as f:\n",
    "        tables_data=json.load(f)\n",
    "\n",
    "    database = {}\n",
    "\n",
    "    \n",
    "    with open(cleanDataPath, 'r') as f:\n",
    "\n",
    "        index=0\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            db_id = data.get('db_id')\n",
    "            query = data.get('query')\n",
    "            question = data.get('question')\n",
    "            query_toks=data.get('query_toks')\n",
    "\n",
    "            if db_id not in nlqex_data: continue\n",
    "\n",
    "            word_freq={}        \n",
    "            for item in tables_data:\n",
    "                if item['db_id']==db_id:\n",
    "                    for table_name in item[\"table_names_original\"]:\n",
    "                        word_freq[table_name.lower()]=1\n",
    "\n",
    "            if db_id not in database:\n",
    "                index=0\n",
    "                database[db_id] = {'query': [], 'question': [], 'query_toks': [], 'tables': [], 'nlqex_tables': []}\n",
    "\n",
    "            interim_map={}\n",
    "            table_list=[]\n",
    "\n",
    "            for query_tok in query_toks:\n",
    "                if query_tok.lower() in word_freq:\n",
    "                    if query_tok.lower() not in interim_map:\n",
    "                        interim_map[query_tok.lower()]=1\n",
    "                        table_list.append(query_tok.lower())\n",
    "            \n",
    "            database[db_id]['query'].append(query)\n",
    "            database[db_id]['question'].append(question)\n",
    "            database[db_id]['query_toks'].append(query_toks)\n",
    "            database[db_id]['tables'].append(table_list)\n",
    "            print(db_id,index)\n",
    "            database[db_id]['nlqex_tables'].append(nlqex_data[db_id][str(index)])\n",
    "            index+=1\n",
    "            \n",
    "\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_array = getDbSchemaMapping('spider/databasee')\n",
    "databases = get_data('spider/tables.json','spider/train_spider_main_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(databases['activity_1']['tables'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(databases))\n",
    "print(len(nlqex_data))\n",
    "print(len(schema_array))\n",
    "# databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database folder path\n",
    "db_folder_path = 'spider/database'\n",
    "\n",
    "def convert_to_list(results):\n",
    "    final_list = []\n",
    "    if not results: return final_list\n",
    "    for row in results:\n",
    "        final_list.append(tuple(sorted(list(row), key=str)))\n",
    "    return final_list\n",
    "\n",
    "def execute_query(database_path, query):\n",
    "    try:\n",
    "        conn = sqlite3.connect(database_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "        conn.close()\n",
    "        return results\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        with open('./incorrectGeminiLog.txt', 'a') as f:\n",
    "            f.write(f\"\\nError that occured:\\n{e}\\n\\n\")\n",
    "        return None\n",
    "\n",
    "def compare_queries(db_name, db_folder_path, generated_query, original_query):\n",
    "    db_path = os.path.join(db_folder_path, db_name, db_name + '.sqlite')\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"Database {db_name} not found.\")\n",
    "        return False\n",
    "\n",
    "    generated_results = execute_query(db_path, generated_query)\n",
    "    original_results = execute_query(db_path, original_query)\n",
    "\n",
    "    # print(generated_results)\n",
    "    # print(original_results)\n",
    "\n",
    "    gen_list = convert_to_list(generated_results)\n",
    "    orig_list = convert_to_list(original_results)\n",
    "\n",
    "    print(gen_list)\n",
    "    print(orig_list)\n",
    "\n",
    "    return Counter(gen_list) == Counter(orig_list)   \n",
    "\n",
    "def extract_sql_query(response):\n",
    "    response=response[::-1]\n",
    "    start = response.find(\"```\")\n",
    "    end = response.find(\"etilqs```\", start + 1)\n",
    "    flag=0\n",
    "    if (end==-1):\n",
    "        flag=1\n",
    "        end = response.find(\"lqs```\")\n",
    "    \n",
    "\n",
    "    if start == -1 or end == -1:\n",
    "        return \"\"\n",
    "    sql_query=\"\"\n",
    "    if flag==1: sql_query = response[start + 3:end].strip()  # Extract the query between ```sql and ```\n",
    "    else: sql_query = response[start + 3:end].strip()\n",
    "    return sql_query[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    numerator=0\n",
    "    for i in range(len(v1)):\n",
    "        numerator+=(v1[i]*v2[i])\n",
    "    if sum(v1)==0 or sum(v2)==0:\n",
    "        return -1\n",
    "    numerator/=math.sqrt(sum(v1))\n",
    "    numerator/=math.sqrt(sum(v2))\n",
    "    return numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_info=[]\n",
    "\n",
    "for dbName, dbSchema in schema_array.items():\n",
    "\n",
    "    if dbName not in databases: continue\n",
    "    if 'tables' not in dbSchema: continue\n",
    "    num_questions=len(databases[dbName]['question'])\n",
    "    num_tables=len(dbSchema['tables'])\n",
    "    if (num_tables==0): continue\n",
    "    if(num_questions==0): continue\n",
    "    info=[num_tables,num_questions]\n",
    "    db_info.append(info)\n",
    "\n",
    "    #filtering out heavy databases\n",
    "    # if num_tables<8 or num_questions<25: continue\n",
    "\n",
    "sorted_list=sorted(db_info, key=lambda x: x[0])\n",
    "for i in sorted_list: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise cross prompt variiables (DANGER: DO NOT PRESS)\n",
    "totalQueries=0\n",
    "correctAns=0\n",
    "notCorrectAns=0\n",
    "accuracy_info={}\n",
    "file_path = 'logs/incorrectGeminiLog.txt'\n",
    "with open(file_path, 'w') as file:\n",
    "    pass\n",
    "file_path = 'logs/geminiLog.txt'\n",
    "with open(file_path, 'w') as file:\n",
    "    pass\n",
    "\n",
    "for dbName, dbSchema in schema_array.items():\n",
    "\n",
    "    if dbName not in databases: continue\n",
    "    if 'tables' not in dbSchema: continue\n",
    "    num_questions=len(databases[dbName]['question'])\n",
    "    num_tables=len(dbSchema['tables'])\n",
    "    if num_questions==0: continue\n",
    "    if num_tables==0: continue\n",
    "\n",
    "    db_folder_path='spider/database'\n",
    "\n",
    "    errorLog=os.path.join(db_folder_path, dbName,'errors.txt')\n",
    "    \n",
    "    with open(errorLog, 'w') as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accuracy_info)\n",
    "totIncor=0\n",
    "totLight=0\n",
    "totHeavy=0\n",
    "lightAcc=[]\n",
    "heavyAcc=[]\n",
    "avgl=0\n",
    "avgh=0\n",
    "for dbName, dbSchema in schema_array.items():\n",
    "    if dbName not in databases: continue\n",
    "    if 'tables' not in dbSchema: continue\n",
    "    num_questions=len(databases[dbName]['question'])\n",
    "    num_tables=len(dbSchema['tables'])\n",
    "    if num_questions==0: continue\n",
    "    if num_tables==0: continue\n",
    "\n",
    "    if dbName in accuracy_info:\n",
    "        print(f\"dbName: {dbName}, Tables: {num_tables}, Correct: {accuracy_info[dbName][0]}, Incorrect: {accuracy_info[dbName][1]}\")\n",
    "        totIncor+=accuracy_info[dbName][1]\n",
    "        if (num_tables<=4):\n",
    "            totLight+=1\n",
    "            lightAcc.append(accuracy_info[dbName][0]/(accuracy_info[dbName][0]+accuracy_info[dbName][1]))\n",
    "            avgl+=accuracy_info[dbName][0]/(accuracy_info[dbName][0]+accuracy_info[dbName][1])\n",
    "        else:\n",
    "            totHeavy+=1\n",
    "            heavyAcc.append(accuracy_info[dbName][0]/(accuracy_info[dbName][0]+accuracy_info[dbName][1]))\n",
    "            avgh+=accuracy_info[dbName][0]/(accuracy_info[dbName][0]+accuracy_info[dbName][1])\n",
    "\n",
    "print(totIncor)\n",
    "print(totLight)\n",
    "print(totHeavy)\n",
    "print(lightAcc)\n",
    "print(heavyAcc)\n",
    "# print(avgl/len(lightAcc))\n",
    "# print(avgh/len(heavyAcc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used='gpt'\n",
    "newInstTot=0\n",
    "final_accuracy = {}\n",
    "\n",
    "for dbName, dbSchema in schema_array.items():\n",
    "    correct_single_table = 0\n",
    "    correct_multi_table = 0\n",
    "    single_table = 0\n",
    "    multi_table = 0\n",
    "\n",
    "    if dbName not in databases: continue\n",
    "    if 'tables' not in dbSchema: continue\n",
    "    num_questions=len(databases[dbName]['question'])\n",
    "    num_tables=len(dbSchema['tables'])\n",
    "    if num_questions==0: continue\n",
    "    if num_tables==0: continue\n",
    "\n",
    "    # #filtering out heavy databases\n",
    "    # if num_tables<8 or num_questions<25: continue\n",
    "\n",
    "    print(f\"Database: {dbName}\")\n",
    "\n",
    "    #initialise entryof the database in accuracy info\n",
    "    if dbName not in accuracy_info:\n",
    "        accuracy_info[dbName]=[0,0]\n",
    "\n",
    "    dbTables=[]\n",
    "    for table in dbSchema[\"tables\"]:\n",
    "        dbTables.append(table[\"name\"].lower())\n",
    "\n",
    "    for i in range(len(databases[dbName]['question'])):\n",
    "        # print(f\"{totalQueries}, {newInstTot}\")\n",
    "        \n",
    "            \n",
    "        newInstTot+=1\n",
    "        if (totalQueries>=(newInstTot)):\n",
    "            continue\n",
    "\n",
    "        # print(f\"{totalQueries}, {newInstTot}\")\n",
    "\n",
    "\n",
    "        tables_used=\"\"\n",
    "        nlqex_tables_used=\"\"\n",
    "\n",
    "\n",
    "        # Iterate through dbNames\n",
    "\n",
    "        for tname in databases[dbName]['tables'][i]:\n",
    "            for tables in dbSchema[\"tables\"]:\n",
    "                if tables[\"name\"].lower() ==tname.lower() :\n",
    "                    tables_used += json.dumps(tables) + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "        #nlq extracted tables\n",
    "\n",
    "        for tname in databases[dbName]['nlqex_tables'][i]:\n",
    "            for tables in dbSchema[\"tables\"]:\n",
    "                if tables[\"name\"].lower() ==tname.lower() :\n",
    "                    nlqex_tables_used += json.dumps(tables) + \"\\n\"\n",
    "\n",
    "\n",
    "        #shots chosen dynamically\n",
    "        \n",
    "        queryVector=[0]*len(dbTables)\n",
    "        for tname in databases[dbName]['tables'][i]:\n",
    "            if tname.lower() in dbTables:\n",
    "                queryVector[dbTables.index(tname.lower())]=1\n",
    "        \n",
    "        shots=[]\n",
    "\n",
    "\n",
    "        for j in range(len(databases[dbName]['question'])):\n",
    "            if abs(j-i)>2:\n",
    "                shotVector=[0]*len(dbTables)\n",
    "                for tname in databases[dbName]['tables'][j]:\n",
    "                    if tname.lower() in dbTables:\n",
    "                        shotVector[dbTables.index(tname.lower())]=1\n",
    "                shots.append([cosine_similarity(queryVector,shotVector),databases[dbName]['question'][j],databases[dbName]['query'][j]])\n",
    "\n",
    "        shots.sort(reverse=True)\n",
    "\n",
    "        dynamicPrompt=\"\\n\\nHere are some more examples:\\n\"\n",
    "\n",
    "        numberOfShots=3\n",
    "        minSimilarity=0.3\n",
    "        maxSimilarity=1\n",
    "\n",
    "        final_shots=[]\n",
    "\n",
    "        count=0\n",
    "        for j in range(len(shots)):\n",
    "            if count==numberOfShots: break\n",
    "            if shots[j][0]<minSimilarity: continue\n",
    "            if shots[j][0]>maxSimilarity: continue\n",
    "            count+=1\n",
    "            final_shots.append(shots[j])\n",
    "            dynamicPrompt+=f\"Example {count}:\\n\\nQuestion:\\n{shots[j][1]}\\n\\nSQL Query:\\n{shots[j][2]}\\n\\n\"\n",
    "\n",
    "\n",
    "        for j in final_shots:\n",
    "            print(j[0])\n",
    "\n",
    "        #prompts used\n",
    "        # tables_used=json.dumps(schema_array[dbName])\n",
    "        initialPrompt=f\"I will feed you schema of a database, store it and then use it to answer the question I will ask related to the database.\\n\"\n",
    "        tablesPrompt = \"Following is the schema of tables you can use to write the SQL Query.\" + \"\\n\" + tables_used + \"\\n\"\n",
    "        nlqTablesPrompt = \"Following are the tables that are highly likely to be used for the given query.\" + \"\\n\" + nlqex_tables_used + \"\\n\"\n",
    "        infoPrompt = \"we are using sqlite as the tool for running the queries. Keep syntax related to it in mind, and provide code accordingly. Dont forget the semicolons wherever needed.\"\n",
    "        columnNamePrompt = \"Be careful with the names of columns. Use precise column names, since changing them (for example making uppercase to lowercase) may lead to error. Also enclose the column names in double quotes to avoid any clashes with reserved keywords.\\n\"\n",
    "        examplePrompt = '''\n",
    "        \\n\\n\\n\n",
    "        Some guidelines to write SQL queries are as follows:\n",
    "\n",
    "        Avoid using = if possible, in situations like in this query:\n",
    "            SELECT\n",
    "            m.Location,\n",
    "            a.Aircraft\n",
    "            FROM `match` AS m\n",
    "            JOIN aircraft AS a\n",
    "            ON m.Winning_Aircraft = a.Aircraft_ID\n",
    "            WHERE\n",
    "            m.Round = (\n",
    "                SELECT\n",
    "                `Round`\n",
    "                FROM `match`\n",
    "                ORDER BY\n",
    "                Fastest_Qualifying\n",
    "                LIMIT 1\n",
    "            );\n",
    "        Here since = is used, m.Round is limited to one row which is not correct.\n",
    "        Also, always check datatypes to ensure that u are understanding the information a column represents correctly. For example, sometimes a column with say name pilot may actually represent its id and not its name.\n",
    "        To help with this, first state your understanding of what the columns actually represent, then walk through the logic for how you are writing the particular query (a stepwise explanation), and then print the final query.\n",
    "        \n",
    "        You can also use joins to extract information. For example:\n",
    "        Question: What are the last names and ages of the students who are allergic to milk and cat?\n",
    "        Tables: Student, Has_Allergy\n",
    "        SQL Query:\n",
    "            SELECT s.LName, s.Age\n",
    "            FROM Student s\n",
    "            JOIN Has_Allergy ha1 ON s.StuID = ha1.StuID\n",
    "            JOIN Has_Allergy ha2 ON s.StuID = ha2.StuID\n",
    "            WHERE ha1.Allergy = 'Milk' AND ha2.Allergy = 'Cat';\n",
    "\n",
    "        Notice how I have joined 3 tables, 2 of which are same. Essentially any table can be joined with any other under suitable constraints.\n",
    "\n",
    "        Also take care of string type columns. Don't confuse singular with plural, for example, egg with eggs. Use the precise string in queries.\n",
    "\n",
    "        When using AND and OR operators together, use parentheses to ensure the correct logical grouping of conditions. For example:\n",
    "        Question: How many female students are allergic to milk or eggs?\n",
    "        Tables: Student, Has_Allergy\n",
    "        Incorrect SQL Query:\n",
    "            SELECT count(*) \n",
    "            FROM has_allergy AS T1 \n",
    "            JOIN Student AS T2 ON T1.StuID = T2.StuID \n",
    "            WHERE T2.sex = \"F\" AND T1.allergy = \"Milk\" OR T1.allergy = \"Eggs\";\n",
    "\n",
    "        Correct SQL Query:\n",
    "            SELECT count(*) \n",
    "            FROM has_allergy AS T1 \n",
    "            JOIN Student AS T2 ON T1.StuID = T2.StuID \n",
    "            WHERE T2.sex = \"F\" AND (T1.allergy = \"Milk\" OR T1.allergy = \"Eggs\");\n",
    "\n",
    "        Notice the use of parentheses to group the OR conditions properly. Always use parentheses to avoid logical errors when combining AND and OR operators.\n",
    "\n",
    "        Also, when there is a column name, say X, present in more than one tables, say both T1 and T2, be very specific of the column you are using in the sql query. So, if u want to use the column from T1,\n",
    "        be sure to use T1.X instead of simply X. This helps avoid the ambiguous column error.  \n",
    "\n",
    "        For eg. \n",
    "\n",
    "        Incorrect SQL Query:\n",
    "            SELECT \"BlockFloor\", COUNT(*) AS \"NumberOfRooms\" \n",
    "            FROM \"Room\" \n",
    "            JOIN \"Block\" ON \"Room\".\"BlockFloor\" = \"Block\".\"BlockFloor\" AND \"Room\".\"BlockCode\" = \"Block\".\"BlockCode\" \n",
    "            GROUP BY \"BlockFloor\";         \n",
    "        Here \"BlockFloor\" column is ambiguous, thus giving error.\n",
    "\n",
    "        Correct Query:\n",
    "            SELECT count(*) ,  T1.blockfloor FROM BLOCK AS T1 JOIN room AS T2 ON T1.blockfloor  =  T2.blockfloor AND T1.blockcode  =  T2.blockcode GROUP BY T1.blockfloor;\n",
    "        The above query corrected ambiguous error by using \"T1.blockfloor\" instead of simply blockfloor, which specified that we meant that the specified column belongs to T1.\n",
    "\n",
    "        If one asks you, say, list people with some specific criteria, then you should try to print names , and print id of the name only if asked specifially.\n",
    "\n",
    "        If, for example, someone asks list of people's names, then use distinct to make sure that a particular person is listed not more than once. For example:\n",
    "        Question: Find the names of nurses who are on call.\n",
    "        Correct Query:\n",
    "            SELECT DISTINCT T1.name FROM nurse AS T1 JOIN on_call AS T2 ON T1.EmployeeID  =  T2.nurse\n",
    "        Notice how using distinct here makes sure that a nurse is not included more than once, since we need only names of the nurses and not other information.\n",
    "\n",
    "        End of guidelines.\n",
    "        \\n\\n\\n\n",
    "        '''\n",
    "        chainOfThoughtPrompt=\"Understand what each column and table mean. State what you understand about the tabel and their relatons. Also state logical steps in between as to how you are constructing the final SQL query.\"\n",
    "        questionPrompt=\"\\n\\nHere is the question part, i.e., the query on the database above, explained in english, for which the corresponding SQL query code is needed.: \\n\\n\\n\" + databases[dbName]['question'][i] + \"\\n\\n\\n\" +  \"\\n\\n\" + \"Provide the SQL query at the end of the response.\\n\"\n",
    "\n",
    "        #with nlqTables\n",
    "        # prompt=initialPrompt+tablesPrompt+nlqTablesPrompt+infoPrompt+columnNamePrompt+examplePrompt+dynamicPrompt+chainOfThoughtPrompt+questionPrompt\n",
    "\n",
    "        #without nlqTables\n",
    "        prompt=initialPrompt+tablesPrompt+infoPrompt+columnNamePrompt+examplePrompt+dynamicPrompt+chainOfThoughtPrompt+questionPrompt\n",
    "\n",
    "        #prompt without shots\n",
    "        promptNoShots=initialPrompt+tablesPrompt+infoPrompt+columnNamePrompt+examplePrompt+chainOfThoughtPrompt+questionPrompt\n",
    "\n",
    "        #get response from LLM\n",
    "        response=printResponse(prompt,model_used)\n",
    "\n",
    "        #get og and gen queries\n",
    "        generated_query = extract_sql_query(response)\n",
    "        original_query = databases[dbName]['query'][i]\n",
    "        if not original_query.endswith(';'):\n",
    "            original_query+=';'\n",
    "\n",
    "        #compare og and gen queries\n",
    "        isSame=compare_queries(dbName, db_folder_path, generated_query, original_query)\n",
    "        is_single_table = False\n",
    "        if (len(databases[dbName]['tables'][i])==1):\n",
    "            is_single_table=True\n",
    "            single_table+=1\n",
    "        else:\n",
    "            multi_table+=1\n",
    "        if(isSame==True):\n",
    "            if is_single_table==True:\n",
    "                correct_single_table+=1\n",
    "            else:\n",
    "                correct_multi_table+=1\n",
    "\n",
    "        #logging\n",
    "        print(f\"Q{totalQueries+1}:\\n\") \n",
    "        if isSame==False:\n",
    "            print(\"The queries do not match.\\n\")\n",
    "            notCorrectAns+=1\n",
    "            accuracy_info[dbName][1]+=1\n",
    "            #logging in incorrectGeminiLog.txt\n",
    "            with open('logs/incorrectGeminiLog.txt', 'a') as f:\n",
    "                f.write(f\"Q{totalQueries+1}:\\n\")\n",
    "                f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "                f.write(f\"LLM_Input:\\n{prompt}\\n\")\n",
    "                # f.write(f\"\\n\\n\\ncosine_similarity: {shots[0][0]} {shots[1][0]} {shots[2][0]}\\n\\n\\n\")\n",
    "                f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "                f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "                f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "                f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "                f.write(f\"\\n\\n\\n\")\n",
    "\n",
    "            errorLog=os.path.join(db_folder_path, dbName,'errors.txt')\n",
    "            with open(errorLog, 'a') as f:\n",
    "                f.write(f\"Q{totalQueries+1}:\\n\")\n",
    "                f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "                f.write(f\"LLM_Input:\\n{prompt}\\n\")\n",
    "                # f.write(f\"\\n\\n\\ncosine_similarity: {shots[0][0]} {shots[1][0]} {shots[2][0]}\\n\\n\\n\")\n",
    "                f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "                f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "                f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "                f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "                f.write(f\"\\n\\n\\n\")\n",
    "\n",
    "        else:\n",
    "            print(\"The queries match.\\n\")\n",
    "            correctAns+=1\n",
    "            accuracy_info[dbName][0]+=1\n",
    "        totalQueries+=1\n",
    "\n",
    "        #logging in geminiLog.txt\n",
    "        with open('logs/geminiLog.txt', 'a') as f:\n",
    "            f.write(f\"Q{totalQueries}:\\n\")\n",
    "            f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "            f.write(f\"LLM_Input:\\n{prompt}\\n\")\n",
    "            # f.write(f\"\\n\\n\\ncosine_similarity: {shots[0][0]} {shots[1][0]} {shots[2][0]}\\n\\n\\n\")\n",
    "            f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "            f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "            f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "            f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "            f.write(f\"Total Queries: {totalQueries}, Correct Answers: {correctAns}, Incorrect Answers: {notCorrectAns}\")\n",
    "            f.write(f\"\\n\\n\\n\")\n",
    "        \n",
    "    final_accuracy[dbName] = {\n",
    "        'correct_single_table': correct_single_table,\n",
    "        'correct_multi_table': correct_multi_table,\n",
    "        'single_table': single_table,\n",
    "        'multi_table': multi_table\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dbName, values in final_accuracy.items():\n",
    "    print(f\"Database: {dbName}\")\n",
    "    print(f\"Tables present: {len(schema_array[dbName]['tables'])}\")\n",
    "    print(f\"Correct single table: {values['correct_single_table']}\")\n",
    "    print(f\"Correct multi table: {values['correct_multi_table']}\")\n",
    "    print(f\"Single table: {values['single_table']}\")\n",
    "    print(f\"Multi table: {values['multi_table']}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schema_array['browser_web']['tables'][0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalQueriesNG=0\n",
    "correctAnsNG=0\n",
    "notCorrectAns=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used='gemini'\n",
    "newInstTot=0\n",
    "for dbName, dbSchema in schema_array.items():\n",
    "    \n",
    "    if dbName not in databases:\n",
    "        continue\n",
    "\n",
    "    print(dbName)\n",
    "\n",
    "    for i in range(len(databases[dbName]['question'])):\n",
    "        # print(f\"{totalQueriesNG}, {newInstTot}\")\n",
    "        newInstTot+=1\n",
    "        if (totalQueriesNG>=(newInstTot)):\n",
    "            continue\n",
    "\n",
    "        # print(f\"{totalQueriesNG}, {newInstTot}\")\n",
    "        tables_used=\"\"\n",
    "\n",
    "        # Iterate through dbNames\n",
    "\n",
    "        for tname in databases[dbName]['tables'][i]:\n",
    "            for tables in dbSchema[\"tables\"]:\n",
    "                if tables[\"name\"].lower() ==tname.lower() :\n",
    "                    tables_used += json.dumps(tables) + \"\\n\"\n",
    "\n",
    "        \n",
    "\n",
    "        #prompts used\n",
    "        tables_used=json.dumps(schema_array[dbName])\n",
    "        initialPrompt=f\"I will feed you schema of a database, store it and then use it to answer the question I will ask related to the database.\\n\"\n",
    "        tablesPrompt = \"Following is the schema of tables you can use to write the SQL Query.\" + \"\\n\\n\" +tables_used + \"\\n\\n\"\n",
    "        infoPrompt = \"we are using sqlite as the tool for running the queries. Keep syntax related to it in mind, and provide code accordingly. Dont forget the semicolons wherever needed.\"\n",
    "        columnNamePrompt = \"Be careful with the names of columns. Use precise column names, since changing them (for example making uppercase to lowercase) may lead to error. Also enclose the column names in double quotes to avoid any clashes with reserved keywords.\\n\"\n",
    "        examplePrompt = '''\n",
    "        Avoid using = if possible, in situations like in this query:\n",
    "                            SELECT\n",
    "                            m.Location,\n",
    "                            a.Aircraft\n",
    "                            FROM `match` AS m\n",
    "                            JOIN aircraft AS a\n",
    "                            ON m.Winning_Aircraft = a.Aircraft_ID\n",
    "                            WHERE\n",
    "                            m.Round = (\n",
    "                                SELECT\n",
    "                                `Round`\n",
    "                                FROM `match`\n",
    "                                ORDER BY\n",
    "                                Fastest_Qualifying\n",
    "                                LIMIT 1\n",
    "                            );\n",
    "                            Here since = is used, m.Round is limited to one row which is not correct.\n",
    "                            Also, always check datatypes to ensure that u are understanding the information a column represents correctly. For example, sometimes a column with say name pilot may actually represent its id and not its name.\n",
    "                            To help with this, first state your understanding of what the columns actually represent, then walk through the logic for how you are writing the particular query (a stepwise explanation), and then print the final query.\n",
    "                            \n",
    "                            You can also use joins to extract information. For example:\n",
    "                            Question: What are the last names and ages of the students who are allergic to milk and cat?\n",
    "                            Tables: Student, Has_Allergy\n",
    "                            SQL Query:\n",
    "                                SELECT s.LName, s.Age\n",
    "                                FROM Student s\n",
    "                                JOIN Has_Allergy ha1 ON s.StuID = ha1.StuID\n",
    "                                JOIN Has_Allergy ha2 ON s.StuID = ha2.StuID\n",
    "                                WHERE ha1.Allergy = 'Milk' AND ha2.Allergy = 'Cat';\n",
    "                            Notice how I have joined 3 tables, 2 of which are same. Essentially any table can be joined with any other under suitable constraints.\n",
    "\n",
    "        Also take care of string type columns. Don't confuse singular with plural, for example, egg with eggs. Use the precise string in queries.\n",
    "\n",
    "        When using AND and OR operators together, use parentheses to ensure the correct logical grouping of conditions. For example:\n",
    "        Question: How many female students are allergic to milk or eggs?\n",
    "        Tables: Student, Has_Allergy\n",
    "        Incorrect SQL Query:\n",
    "            SELECT count(*) \n",
    "            FROM has_allergy AS T1 \n",
    "            JOIN Student AS T2 ON T1.StuID = T2.StuID \n",
    "            WHERE T2.sex = \"F\" AND T1.allergy = \"Milk\" OR T1.allergy = \"Eggs\";\n",
    "\n",
    "        Correct SQL Query:\n",
    "            SELECT count(*) \n",
    "            FROM has_allergy AS T1 \n",
    "            JOIN Student AS T2 ON T1.StuID = T2.StuID \n",
    "            WHERE T2.sex = \"F\" AND (T1.allergy = \"Milk\" OR T1.allergy = \"Eggs\");\n",
    "\n",
    "        Notice the use of parentheses to group the OR conditions properly. Always use parentheses to avoid logical errors when combining AND and OR operators.\n",
    "\n",
    "        Also, when there is a column name, say X, present in more than one tables, say both T1 and T2, be very specific of the column you are using in the sql query. So, if u want to use the column from T1,\n",
    "        be sure to use T1.X instead of simply X. This helps avoid the ambiguous column error.   \n",
    "\n",
    "        '''\n",
    "        chainOfThoughtPrompt=\"Understand what each column and table mean. State what you understand about the tabel and their relatons. Also state logical steps in between as to how you are constructing the final SQL query.\"\n",
    "        questionPrompt=\"\\nHere is the question part, i.e., the query on the database above, explained in english, for which the corresponding SQL query code is needed.: \\n\\n\" + databases[dbName]['question'][i] + \"\\n\\n\" +  \"\\n\" + \"Provide the SQL query at the end of the response.\\n\"\n",
    "\n",
    "        prompt=initialPrompt+tablesPrompt+infoPrompt+columnNamePrompt+examplePrompt+chainOfThoughtPrompt+questionPrompt\n",
    "\n",
    "        #get response from LLM\n",
    "        response=printResponse(prompt,model_used)\n",
    "\n",
    "        #get og and gen queries\n",
    "        generated_query = extract_sql_query(response)\n",
    "        original_query = databases[dbName]['query'][i]\n",
    "        if not original_query.endswith(';'):\n",
    "            original_query+=';'\n",
    "\n",
    "        #compare og and gen queries\n",
    "        isSame=compare_queries(dbName, db_folder_path, generated_query, original_query)\n",
    "\n",
    "        #logging\n",
    "        print(f\"Q{totalQueriesNG+1}:\\n\") \n",
    "        if isSame==False:\n",
    "            print(\"The queries do not match.\\n\")\n",
    "            notCorrectAnsNG+=1\n",
    "\n",
    "            #logging in incorrectGeminiLog.txt\n",
    "            with open('logs/incorrectGeminiLogNoGolden.txt', 'a') as f:\n",
    "                f.write(f\"Q{totalQueriesNG+1}:\\n\")\n",
    "                f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "                f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "                f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "                f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "                f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "                f.write(f\"\\n\\n\\n\")\n",
    "\n",
    "        else:\n",
    "            print(\"The queries match.\\n\")\n",
    "            correctAnsNG+=1\n",
    "        totalQueriesNG+=1\n",
    "\n",
    "        #logging in geminiLog.txt\n",
    "        with open('logs/geminiLogNoGolden.txt', 'a') as f:\n",
    "            f.write(f\"Q{totalQueriesNG}:\\n\")\n",
    "            f.write(f\"Prompt Tables:\\n{tables_used}\\n\")\n",
    "            f.write(f\"LLM_response:\\n{response}\\n\")\n",
    "            f.write(f\"Question:\\n\\n{databases[dbName]['question'][i]}\\n\\n\")\n",
    "            f.write(f\"Original_query:\\n\\n{original_query}\\n\\n\")\n",
    "            f.write(f\"generated_query:\\n\\n{generated_query}\\n\\n\")\n",
    "            f.write(f\"Total Queries: {totalQueriesNG}, Correct Answers: {correctAnsNG}, Incorrect Answers: {notCorrectAnsNG}\")\n",
    "            f.write(f\"\\n\\n\\n\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_list = ['physician', 'department', 'affiliated_with', 'procedures', 'trained_in', 'patient', 'nurse', 'appointment', 'medication', 'prescribes', 'block', 'room', 'on_call', 'stay', 'undergoes']\n",
    "STprompt = \"I will feed you the schema of a database, give me a description of the database using the tabluar information. Describe each table present in the schema in one or two lines. Here is the schema \\n\\n\" + str(schema_array['hospital_1'])+'\\n\\n'\n",
    "print(printResponse(STprompt,'gemini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(databases['hospital_1']['question'])\n",
    "\n",
    "for q in databases['hospital_1']['question']:\n",
    "    print(f\"\\\"{q}\\\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_extraction_prompt2 = \"Give a detailed description of each table in the database. I have provided you the schema which contains the column names. I have also provided sample data, which is essentially the first row of the table, for better understanding. Use all the information to understand the table deeply, and provid information about it. The information should include what each column of the table contains, as well. We will be using the information you provide for extracting queries that use this table. Also, all information should be in the fomr of a single paragraph. The response should be # Table table_name table_description ! .\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
